// frontend/src/components/challenge/VoiceRecorder.tsx
'use client';

import { Button } from '@/components/ui/button';
import { Mic, Square, Upload } from 'lucide-react';
import { useRef, useState } from 'react';

interface VoiceRecorderProps {
  onTranscriptionComplete: (text: string, feedback: any) => void;
  isLoading?: boolean;
}

export function VoiceRecorder({ 
  onTranscriptionComplete, 
  isLoading = false 
}: VoiceRecorderProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [recordingMethod, setRecordingMethod] = useState<'web' | 'upload'>('web');
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);

  // Web Speech API (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ )
  const startWebSpeech = () => {
    if (!('webkitSpeechRecognition' in window)) {
      alert('ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“');
      return;
    }

    const recognition = new (window as any).webkitSpeechRecognition();
    recognition.continuous = false;
    recognition.interimResults = true;
    recognition.lang = 'en-US'; // è‹±èªè¨­å®š
    recognition.maxAlternatives = 1;

    recognition.onstart = () => {
      setIsRecording(true);
    };

    recognition.onresult = async (event: any) => {
      const transcript = event.results[0][0].transcript;
      const confidence = event.results[0][0].confidence;
      
      console.log('Web Speechçµæœ:', { transcript, confidence });
      
      // AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å–å¾—ï¼ˆæ—¢å­˜APIã‚µãƒ¼ãƒ“ã‚¹ã¨ã®çµ±åˆï¼‰
      try {
        const { voiceRecorderAPI } = await import('@/services/apiIntegration');
        const { transcript: processedText, feedback, error } = await voiceRecorderAPI.processWebSpeechWithFeedback(transcript, confidence);
        
        if (error) {
          console.error('ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å–å¾—ã‚¨ãƒ©ãƒ¼:', error);
          onTranscriptionComplete(transcript, null);
        } else {
          onTranscriptionComplete(processedText, feedback);
        }
      } catch (error) {
        console.error('ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å–å¾—ã‚¨ãƒ©ãƒ¼:', error);
        onTranscriptionComplete(transcript, null);
      }
    };

    recognition.onerror = (event: any) => {
      console.error('éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:', event.error);
      setIsRecording(false);
    };

    recognition.onend = () => {
      setIsRecording(false);
    };

    recognition.start();
  };

  // MediaRecorder API (é«˜å“è³ª)
  const startMediaRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      });

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });

      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm' });
        await uploadAudioFile(audioBlob);
        
        // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
        stream.getTracks().forEach(track => track.stop());
      };

      setIsRecording(true);
      mediaRecorder.start();

      // 30ç§’ã§è‡ªå‹•åœæ­¢
      setTimeout(() => {
        if (mediaRecorder.state === 'recording') {
          stopRecording();
        }
      }, 30000);

    } catch (error) {
      console.error('éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:', error);
      alert('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ');
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }
    setIsRecording(false);
  };

  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæ—¢å­˜APIã‚µãƒ¼ãƒ“ã‚¹ã¨ã®çµ±åˆï¼‰
  const uploadAudioFile = async (audioBlob: Blob) => {
    try {
      const { voiceRecorderAPI } = await import('@/services/apiIntegration');
      const { transcript, feedback, confidence, error } = await voiceRecorderAPI.processAudioFileWithFeedback(audioBlob);

      if (error) {
        console.error('éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼:', error);
        onTranscriptionComplete('', { error });
      } else {
        console.log('Google Speechçµæœ:', { transcript, confidence });
        onTranscriptionComplete(transcript, feedback);
      }
    } catch (error) {
      console.error('éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼:', error);
      onTranscriptionComplete('', { error: 'éŸ³å£°å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ' });
    }
  };

  // ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
  const handleFileUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ (5MBåˆ¶é™)
    if (file.size > 5 * 1024 * 1024) {
      alert('ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ï¼ˆ5MBä»¥ä¸‹ã«ã—ã¦ãã ã•ã„ï¼‰');
      return;
    }

    await uploadAudioFile(file);
  };

  return (
    <div className="space-y-4">
      {/* éŒ²éŸ³æ–¹æ³•é¸æŠ */}
      <div className="flex gap-2 mb-4">
        <Button
          variant={recordingMethod === 'web' ? 'default' : 'outline'}
          onClick={() => setRecordingMethod('web')}
          size="sm"
        >
          ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èªè­˜
        </Button>
        <Button
          variant={recordingMethod === 'upload' ? 'default' : 'outline'}
          onClick={() => setRecordingMethod('upload')}
          size="sm"
        >
          é«˜å“è³ªéŒ²éŸ³
        </Button>
      </div>

      {/* éŒ²éŸ³ãƒœã‚¿ãƒ³ */}
      {recordingMethod === 'web' ? (
        <Button
          onClick={startWebSpeech}
          disabled={isRecording || isLoading}
          className={`w-full ${isRecording ? 'bg-red-500 animate-pulse' : 'bg-blue-500'}`}
        >
          <Mic className="mr-2" />
          {isRecording ? 'è©±ã—ã¦ãã ã•ã„...' : 'éŒ²éŸ³é–‹å§‹ (Web Speech)'}
        </Button>
      ) : (
        <div className="space-y-2">
          <Button
            onClick={isRecording ? stopRecording : startMediaRecording}
            disabled={isLoading}
            className={`w-full ${isRecording ? 'bg-red-500 animate-pulse' : 'bg-green-500'}`}
          >
            {isRecording ? <Square className="mr-2" /> : <Mic className="mr-2" />}
            {isRecording ? 'éŒ²éŸ³åœæ­¢' : 'é«˜å“è³ªéŒ²éŸ³é–‹å§‹'}
          </Button>
          
          {/* ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ */}
          <div className="relative">
            <input
              type="file"
              accept="audio/*"
              onChange={handleFileUpload}
              className="absolute inset-0 w-full h-full opacity-0 cursor-pointer"
              disabled={isLoading}
            />
            <Button variant="outline" className="w-full" disabled={isLoading}>
              <Upload className="mr-2" />
              éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            </Button>
          </div>
        </div>
      )}

      {/* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º */}
      {isRecording && (
        <div className="text-center text-sm text-gray-600">
          ğŸ¤ éŒ²éŸ³ä¸­... (æœ€å¤§30ç§’)
        </div>
      )}
      
      {isLoading && (
        <div className="text-center text-sm text-gray-600">
          ğŸ¤– AIåˆ†æä¸­...
        </div>
      )}
    </div>
  );
}